{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3377b6b4",
   "metadata": {
    "tags": [
     "Parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: isodate in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: six in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from isodate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1b6e7",
   "metadata": {
    "tags": [
     "Parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import dateutil.parser\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from config import params  # Import parameters from the config file\n",
    "\n",
    "# Extract parameters for MongoDB connection\n",
    "mongo_host = params['mongo_host']\n",
    "mongo_port = params['mongo_port']\n",
    "db_name = params['db_name']\n",
    "collection_name = params['collection_name']\n",
    "last_timestamp_collection_name = params['last_timestamp_collection_name']\n",
    "cohort_all_collection = params['cohort_all_collection']\n",
    "\n",
    "# Establish MongoDB connection\n",
    "client = pymongo.MongoClient(f\"mongodb://{mongo_host}:{mongo_port}\")\n",
    "db = client[db_name]\n",
    "\n",
    "#class processing_data:\n",
    "#############Sub Functions ################\n",
    "\n",
    "# Define the update_last_processed_timestamp_to_db function\n",
    "def update_last_processed_timestamp_to_db(timestamp):\n",
    "    print('timestamp:', timestamp, \"collection:\", last_timestamp_collection_name)\n",
    "    last_timestamp_collection = db[last_timestamp_collection_name].update_one({}, {\"$set\": {\"last_processed_timestamp\": timestamp}}, upsert=True)\n",
    "    print('update output', last_timestamp_collection)\n",
    "    cursor = db[last_timestamp_collection_name].find({})\n",
    "    documents = list(cursor)\n",
    "    cursor.close()\n",
    "\n",
    "def process_since_last_timestamp(last_timestamp):\n",
    "    vtime = {'Timestamp': {'$gt': last_timestamp}}\n",
    "    cursor = db[collection_name].find(vtime)\n",
    "    documents = list(cursor)\n",
    "    \n",
    "    ## karu for time being neeed to check it out cursor.close()\n",
    "    \n",
    "    cdc_data = pd.DataFrame(documents)\n",
    "\n",
    "    if len(cdc_data) == 0:\n",
    "        print('No records processed...')\n",
    "    else:\n",
    "        max_timestamp = cdc_data['Timestamp'].max()\n",
    "        update_last_processed_timestamp_to_db(max_timestamp)\n",
    "\n",
    "    return cdc_data\n",
    "\n",
    "def process_all_records():\n",
    "    cursor = db[collection_name].find({})\n",
    "    documents = list(cursor)\n",
    "    cursor.close()\n",
    "\n",
    "    cdc_data = pd.DataFrame(documents)\n",
    "\n",
    "    cdc_data['Timestamp'] = pd.to_datetime(cdc_data['Timestamp'])\n",
    "\n",
    "    if len(cdc_data) == 0:\n",
    "        print('No records processed...')\n",
    "    else:\n",
    "        max_timestamp = cdc_data['Timestamp'].max()\n",
    "        print('Timestamp of last processed data:', max_timestamp)\n",
    "        update_last_processed_timestamp_to_db(max_timestamp)\n",
    "\n",
    "    return cdc_data\n",
    "\n",
    "def get_last_processed_timestamp():\n",
    "    update_last_processed_timestamp_to_db(0)\n",
    "\n",
    "    last_timestamp_collection = db[last_timestamp_collection_name]\n",
    "    last_processed_timestamp = last_timestamp_collection.find_one({}).get('last_processed_timestamp')\n",
    "\n",
    "    print('last_processed_timestamp:', last_processed_timestamp)\n",
    "\n",
    "    if last_processed_timestamp == 0 or last_processed_timestamp is None or pd.isnull(last_processed_timestamp):\n",
    "        print('Processing all records')\n",
    "        cdc_data = process_all_records()\n",
    "    else:\n",
    "        if last_processed_timestamp == 0:\n",
    "            print('Processing all records since it is 0')\n",
    "            cdc_data = process_all_records()\n",
    "        else:\n",
    "            print('Processing cdc records:')\n",
    "            print(last_processed_timestamp)\n",
    "            cdc_data = process_since_last_timestamp(last_processed_timestamp)\n",
    "\n",
    "    client.close()\n",
    "\n",
    "    return cdc_data\n",
    "\n",
    "# Call the get_last_processed_timestamp function\n",
    "fcdc_data = get_last_processed_timestamp()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(fcdc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcdc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e21151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Your existing functions remain unchanged\n",
    "def assign_numeric_label(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return '1'\n",
    "    elif 6 <= hour < 12:\n",
    "        return '2'\n",
    "    elif 12 <= hour < 18:\n",
    "        return '3'\n",
    "    else:\n",
    "        return '4'\n",
    "\n",
    "def find_max_values(df):\n",
    "    label_cols = ['1', '2', '3', '4']\n",
    "    \n",
    "    for col in label_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  \n",
    "    \n",
    "    df['recommended_hr'] = df[label_cols].max(axis=1)\n",
    "    df['hr_id'] = df[label_cols].idxmax(axis=1)\n",
    "    max_counts = df[label_cols].eq(df['recommended_hr'], axis=0).sum(axis=1)\n",
    "    multiple_max = df[max_counts > 1].index\n",
    "    random_column = random.choice(label_cols)\n",
    "    return df, multiple_max, random_column\n",
    "\n",
    "def process_emaildata(vgroup):\n",
    "    vgroup['Timestamp'] = pd.to_datetime(vgroup['Timestamp'])\n",
    "    vgroup['DayOfWeek'] = vgroup['Timestamp'].dt.dayofweek \n",
    "    vgroup['Timestamp'] = vgroup['Timestamp'].dt.hour.apply(assign_numeric_label)\n",
    "    \n",
    "    weekdays = vgroup[vgroup['DayOfWeek'] < 5]\n",
    "    weekends = vgroup[vgroup['DayOfWeek'] >= 5]\n",
    "    \n",
    "    vgroupings = ['Event', 'Holiday','Timestamp']\n",
    "    weekday_final = pd.concat([weekdays.groupby(['Emailid', col]).size().unstack(fill_value=0) for col in vgroupings], axis=1)\n",
    "    weekend_final = pd.concat([weekends.groupby(['Emailid', col]).size().unstack(fill_value=0) for col in vgroupings], axis=1)\n",
    "    \n",
    "    weekday_final, weekday_multiple_max, random_col_weekday = find_max_values(weekday_final)\n",
    "    weekend_final, weekend_multiple_max, random_col_weekend = find_max_values(weekend_final)\n",
    "    \n",
    "    weekday_final.rename(columns={'recommended_hr': 'w_rec_hr'}, inplace=True)\n",
    "    weekend_final.rename(columns={'recommended_hr': 'we_rec_hr'}, inplace=True)\n",
    "    \n",
    "    return weekday_final, weekend_final, weekday_multiple_max, weekend_multiple_max, random_col_weekday, random_col_weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = df.groupby('Emailid')\n",
    "grouped = fcdc_data.groupby('Emailid')\n",
    "weekday_email_data = []\n",
    "weekend_email_data = []\n",
    "weekday_multiple_max_values = []\n",
    "weekend_multiple_max_values = []\n",
    "weekday_random_cols = []\n",
    "weekend_random_cols = []\n",
    "\n",
    "for vname, vgroup in grouped:\n",
    "    (weekday_processed_data, weekend_processed_data,\n",
    "     weekday_multiple_max, weekend_multiple_max,\n",
    "     random_col_weekday, random_col_weekend) = process_emaildata(vgroup)\n",
    "    \n",
    "    weekday_email_data.append(weekday_processed_data)\n",
    "    weekend_email_data.append(weekend_processed_data)\n",
    "    weekday_multiple_max_values.append(weekday_multiple_max)\n",
    "    weekend_multiple_max_values.append(weekend_multiple_max)\n",
    "    weekday_random_cols.append(random_col_weekday)\n",
    "    weekend_random_cols.append(random_col_weekend)\n",
    "\n",
    "weekday_result = pd.concat(weekday_email_data)\n",
    "weekend_result = pd.concat(weekend_email_data)\n",
    "\n",
    "weekday_result.fillna(0, inplace=True)\n",
    "weekend_result.fillna(0, inplace=True)\n",
    "\n",
    "combined_result = pd.concat([weekday_result, weekend_result], axis=1)\n",
    "\n",
    "\n",
    "combined_result['weekday_cohort_id'] = np.where(combined_result['w_rec_hr'] >= combined_result['we_rec_hr'],combined_result['w_rec_hr'],0)\n",
    "\n",
    "combined_result['weekend_cohort_id'] = np.where(combined_result['we_rec_hr'] > combined_result['w_rec_hr'],combined_result['we_rec_hr'],0)\n",
    "\n",
    "\n",
    "equal_scores = combined_result['w_rec_hr'] == combined_result['we_rec_hr']\n",
    "indices = equal_scores[equal_scores].index\n",
    "\n",
    "for index in indices:\n",
    "    if combined_result.loc[index, 'weekday_cohort_id'] == combined_result.loc[index, 'weekend_cohort_id']:\n",
    "        random_column = np.random.choice(['weekday_cohort_id', 'weekend_cohort_id'])\n",
    "        value = combined_result.loc[index, random_column]\n",
    "        combined_result.loc[index, 'weekday_cohort_id'] = value\n",
    "        combined_result.loc[index, 'weekend_cohort_id'] = 0 if random_column == 'weekday_cohort_id' else value\n",
    "combined_result.reset_index(inplace=True)\n",
    "print(\"Combined Data with 'weekday_cohort_id' and 'weekend_cohort_id' columns:\")\n",
    "print(combined_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51366c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74de381",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result.columns = combined_result.columns.astype(str)\n",
    "\n",
    "# Create MongoDB client and connect to the database\n",
    "mongo_uri = f\"mongodb://{mongo_host}:{mongo_port}\"\n",
    "client = pymongo.MongoClient(mongo_uri)\n",
    "db = client[db_name]\n",
    "collection = db[cohort_all_collection]\n",
    "\n",
    "data_to_insert = combined_result.to_dict(orient=\"records\")\n",
    "\n",
    "data_to_insert = [{str(key): value for key, value in doc.items()} for doc in data_to_insert]\n",
    "\n",
    "collection.insert_many(data_to_insert)\n",
    "\n",
    "client.close()\n",
    "\n",
    "print(\"Data has been successfully saved to the MongoDB database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_result.to_csv('cohort_all_outpute_testing1.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
